{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d31dd9e",
   "metadata": {},
   "source": [
    "## Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790f7845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn_extensions import TabPFNRegressor\n",
    "from tabpfn_extensions.rf_pfn import (\n",
    "    RandomForestTabPFNClassifier,\n",
    "    RandomForestTabPFNRegressor,\n",
    ")\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# %matplotlib inline\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, TargetEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.linear_model import Lars, LassoLars, OrthogonalMatchingPursuit\n",
    "from sklearn.linear_model import BayesianRidge, ARDRegression, PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import RANSACRegressor, TheilSenRegressor, HuberRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from typing import List, Tuple, Optional\n",
    "warnings.filterwarnings('ignore')\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser(description=\"stacking\")\n",
    "parser.add_argument('--scaler', default=\"standard\", type=str) # standard or minmax or robust\n",
    "parser.add_argument('--cv', default=10, type=int)\n",
    "parser.add_argument('--seed', default=42, type=int)\n",
    "args = parser.parse_args('')\n",
    "scaler = args.scaler\n",
    "cv = args.cv\n",
    "seed = args.seed\n",
    "if scaler == \"standard\":    scaler = StandardScaler()\n",
    "elif scaler == \"minmax\":    scaler = MinMaxScaler()\n",
    "elif scaler == \"robust\":    scaler = RobustScaler()\n",
    "\n",
    "def set_seeds(seed=seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seeds()\n",
    "\n",
    "idx = f\"{parser.description}\"\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf35c1f2",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3283d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 컬럼명 매핑(dict)을 파일 내부에 정의 ──\n",
    "TRAIN_COL_RENAMES = {\n",
    "    '건물번호': 'building_number',\n",
    "    '일시': 'date_time',\n",
    "    '기온(°C)': 'temperature',\n",
    "    '강수량(mm)': 'rainfall',\n",
    "    '풍속(m/s)': 'windspeed',\n",
    "    '습도(%)': 'humidity',\n",
    "    '일조(hr)': 'sunshine',\n",
    "    '일사(MJ/m2)': 'solar_radiation',\n",
    "    '전력소비량(kWh)': 'power_consumption'\n",
    "}\n",
    "TEST_COL_RENAMES = TRAIN_COL_RENAMES.copy()\n",
    "\n",
    "BUILDING_INFO_RENAMES = {\n",
    "    '건물번호': 'building_number',\n",
    "    '건물유형': 'building_type',\n",
    "    '연면적(m2)': 'total_area',\n",
    "    '냉방면적(m2)': 'cooling_area',\n",
    "    '태양광용량(kW)': 'solar_power_capacity',\n",
    "    'ESS저장용량(kWh)': 'ess_capacity',\n",
    "    'PCS용량(kW)': 'pcs_capacity'\n",
    "}\n",
    "TYPE_TRANSLATION = {\n",
    "    '건물기타': 'Other Buildings',\n",
    "    '공공': 'Public',\n",
    "    '학교': 'School',\n",
    "    '백화점': 'Department Store',\n",
    "    '병원': 'Hospital',\n",
    "    '상용': 'Commercial',\n",
    "    '아파트': 'Apartment',\n",
    "    '연구소': 'Research Institute',\n",
    "    '호텔': 'Hotel',\n",
    "    'IDC(전화국)': 'IDC'\n",
    "}\n",
    "\n",
    "def load_raw(data_dir: str = \"../data/raw\"):\n",
    "    train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "    test  = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n",
    "    info  = pd.read_csv(os.path.join(data_dir, 'building_info.csv'))\n",
    "    return train, test, info\n",
    "\n",
    "def rename_columns(df: pd.DataFrame, mapping: dict):\n",
    "    df = df.rename(columns=mapping)\n",
    "    if 'num_date_time' in df.columns:\n",
    "        df = df.drop('num_date_time', axis=1)\n",
    "    return df\n",
    "\n",
    "def preprocess_building_info(info: pd.DataFrame) -> pd.DataFrame:\n",
    "    info = info.rename(columns=BUILDING_INFO_RENAMES)\n",
    "    info['building_type'] = info['building_type'].replace(TYPE_TRANSLATION)\n",
    "    return info\n",
    "\n",
    "def merge_datasets(train: pd.DataFrame, test: pd.DataFrame, info: pd.DataFrame):\n",
    "    train = train.merge(info, on='building_number', how='left')\n",
    "    test  = test.merge(info, on='building_number', how='left')\n",
    "    return train, test\n",
    "\n",
    "def save_processed(df: pd.DataFrame, name: str, out_dir: str = \"../data/processed\"):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    path = os.path.join(out_dir, f\"{name}.pkl\")\n",
    "    df.to_pickle(path)\n",
    "    print(f\"Saved processed data to: {path}\")\n",
    "\n",
    "def load_and_process(data_dir: str = \"../data/raw\") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    1) raw CSV 로드\n",
    "    2) 컬럼명 리네임\n",
    "    3) building_info 전처리 & 병합\n",
    "    4) processed/train.pkl, processed/test.pkl 저장\n",
    "    5) train_df, test_df 반환\n",
    "    \"\"\"\n",
    "    train, test, info = load_raw(data_dir)\n",
    "    train = rename_columns(train, TRAIN_COL_RENAMES)\n",
    "    test  = rename_columns(test, TEST_COL_RENAMES)\n",
    "    info  = preprocess_building_info(info)\n",
    "    train, test = merge_datasets(train, test, info)\n",
    "\n",
    "    save_processed(train, \"train\")\n",
    "    save_processed(test,  \"test\")\n",
    "    return train, test\n",
    "\n",
    "# (Optional) 기존 save → load 편의 함수\n",
    "def load_processed(name: str, proc_dir: str = \"../data/processed\") -> pd.DataFrame:\n",
    "    path = os.path.join(proc_dir, f\"{name}.pkl\")\n",
    "    return pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6601d11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEEK_H = 168      # 1주일 = 168시간\n",
    "EPS    = 1e-3    \n",
    "def create_datetime(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    date_time 컬럼을 datetime 타입으로 변환하고\n",
    "    시간, 일, 월, 요일, 주말 여부, 연중 일(day_of_year) 피처 및\n",
    "    하루를 4분할하는 시간대(time_of_day) 피처 추가\n",
    "    \"\"\"\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'], format='%Y%m%d %H')\n",
    "    df['hour'] = df['date_time'].dt.hour\n",
    "    df['day'] = df['date_time'].dt.day\n",
    "    df['month'] = df['date_time'].dt.month\n",
    "    df['day_of_week'] = df['date_time'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    df['day_of_year'] = df['date_time'].dt.dayofyear\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_summer_cycle_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    여름 기간을 주기로 하는 sin/cos 특성을 생성합니다.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    start_date = datetime.strptime(\"2024-05-20 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "    end_date = datetime.strptime(\"2024-09-08 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "    period_seconds = (end_date - start_date).total_seconds()\n",
    "    \n",
    "    def summer_cos(date):\n",
    "        return np.cos(2 * np.pi * (date - start_date).total_seconds() / period_seconds)\n",
    "    \n",
    "    def summer_sin(date):\n",
    "        return np.sin(2 * np.pi * (date - start_date).total_seconds() / period_seconds)\n",
    "        \n",
    "    df_copy['summer_cos'] = df_copy['date_time'].apply(summer_cos)\n",
    "    df_copy['summer_sin'] = df_copy['date_time'].apply(summer_sin)\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def add_squared_features(\n",
    "    df: pd.DataFrame, \n",
    "    target_cols: List[str] = ['temperature', 'humidity']\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    지정된 컬럼에 대해 제곱(squared) 특성을 생성합니다.\n",
    "    변수가 타겟에 미치는 비선형 관계를 모델이 학습하는 데 도움을 줍니다.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): 특성을 추가할 데이터프레임\n",
    "        target_cols (List[str]): 제곱할 대상 컬럼 리스트\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 제곱 특성이 추가된 데이터프레임\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    for col in target_cols:\n",
    "        df_copy[f'{col}_squared'] = df_copy[col] ** 2\n",
    "    return df_copy\n",
    "def week_cycle_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    if 'day_of_week' not in df.columns:\n",
    "        df['day_of_week'] = pd.to_datetime(df['date_time']).dt.weekday\n",
    "    if 'hour' not in df.columns:\n",
    "        df['hour'] = pd.to_datetime(df['date_time']).dt.hour\n",
    "    how = df['day_of_week'] * 24 + df['hour']\n",
    "    df['sin_how_1'] = np.sin(2 * np.pi * how / 168)\n",
    "    df['cos_how_1'] = np.cos(2 * np.pi * how / 168)\n",
    "    return df\n",
    "\n",
    "def create_cyclic_features(df):\n",
    "    # hour: 0–23\n",
    "    df['sin_hour'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['cos_hour'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    # (선택) 날짜 전체 주기: day_of_year 1–365 or 366\n",
    "    df['sin_doy'] = np.sin(2 * np.pi * (df['day_of_year'] - 1) / 365)\n",
    "    df['cos_doy'] = np.cos(2 * np.pi * (df['day_of_year'] - 1) / 365)\n",
    "    return df\n",
    "\n",
    "def cooling_degree_hour(temperature, window=12, base_temp=26):\n",
    "    cdhs = []\n",
    "    temps = temperature.values\n",
    "    for i in range(len(temps)):\n",
    "        if i < window:\n",
    "            cdh = np.sum(np.maximum(temps[:i+1] - base_temp, 0))\n",
    "        else:\n",
    "            cdh = np.sum(np.maximum(temps[i-window+1:i+1] - base_temp, 0))\n",
    "        cdhs.append(cdh)\n",
    "    return cdhs\n",
    "\n",
    "def add_cdh_feature(df: pd.DataFrame,\n",
    "                    window: int = 12,\n",
    "                    base_temp: float = 26.0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    건물별 온도 데이터를 이용해 CDH 피처 추가 (cooling_degree_hour 기반)\n",
    "    \"\"\"\n",
    "    cdhs_all = []\n",
    "    for b in df['building_number'].unique():\n",
    "        temps = df.loc[df['building_number'] == b, 'temperature']\n",
    "        cdhs_all.extend(cooling_degree_hour(temps, window=window, base_temp=base_temp))\n",
    "    df['CDH'] = cdhs_all\n",
    "    return df\n",
    "\n",
    "def add_cdd_feature(df: pd.DataFrame,base_temp: float = 18.0,\n",
    "                    window:    int   = 24) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cooling Degree Days (CDD) 추가\n",
    "      - base_temp (°C) 보다 높을 때만 (T - base_temp) 합산\n",
    "      - window 시간 롤링 합산 (min_periods=1)\n",
    "    \"\"\"\n",
    "    # 1) per-hour 초과분 계산\n",
    "    df['excess'] = (df['temperature'] - base_temp).clip(lower=0)\n",
    "    df['CDD'] = (df.groupby('building_number')['excess']                 .transform(lambda s: s.rolling(window, min_periods=1).sum())                )\n",
    "    df.drop(columns=['excess'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def add_thi_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Temperature-Humidity Index (THI) 추가\n",
    "    \"\"\"\n",
    "    df['THI'] = (9/5 * df['temperature'] \n",
    "                 - 0.55 * (1 - df['humidity']/100) \n",
    "                 * (9/5 * df['temperature'] - 26) \n",
    "                 + 32)\n",
    "    return df\n",
    "def add_wct_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Wind Chill Temperature (WCT) 추가\n",
    "    \"\"\"\n",
    "    v16 = df['windspeed'] ** 0.16\n",
    "    df['WCT'] = (13.12 \n",
    "                 + 0.6215 * df['temperature'] \n",
    "                 - 11.37 * v16 \n",
    "                 + 0.3965 * v16 * df['temperature'])\n",
    "    return df\n",
    "\n",
    "def add_temp_features(data):\n",
    "    avg_temp = (\n",
    "        pd.pivot_table(\n",
    "            data[data['hour'] % 3 == 0],\n",
    "            values='temperature',\n",
    "            index=['building_number', 'day', 'month'],\n",
    "            aggfunc='mean'\n",
    "        )\n",
    "        .reset_index()\n",
    "        .rename(columns={'temperature': 'avg_temp'})\n",
    "    )\n",
    "    data = pd.merge(data, avg_temp, on=['building_number', 'day', 'month'], how='left')\n",
    "\n",
    "    max_temp = (\n",
    "        pd.pivot_table(\n",
    "            data,\n",
    "            values='temperature',\n",
    "            index=['building_number', 'day', 'month'],\n",
    "            aggfunc='max'\n",
    "        )\n",
    "        .reset_index()\n",
    "        .rename(columns={'temperature': 'max_temp'})\n",
    "    )\n",
    "    data = pd.merge(data, max_temp, on=['building_number', 'day', 'month'], how='left')\n",
    "\n",
    "    min_temp = (\n",
    "        pd.pivot_table(\n",
    "            data,\n",
    "            values='temperature',\n",
    "            index=['building_number', 'day', 'month'],\n",
    "            aggfunc='min'\n",
    "        )\n",
    "        .reset_index()\n",
    "        .rename(columns={'temperature': 'min_temp'})\n",
    "    )\n",
    "    data = pd.merge(data, min_temp, on=['building_number', 'day', 'month'], how='left')\n",
    "\n",
    "    data['temp_diff'] = data['max_temp'] - data['min_temp']\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def add_humid_features(data):\n",
    "    avg_humid = (\n",
    "        pd.pivot_table(\n",
    "            data[data['hour'] % 3 == 0],\n",
    "            values='humidity',\n",
    "            index=['building_number', 'day', 'month'],\n",
    "            aggfunc='mean'\n",
    "        )\n",
    "        .reset_index()\n",
    "        .rename(columns={'humidity': 'avg_humid'})\n",
    "    )\n",
    "    data = pd.merge(data, avg_humid, on=['building_number', 'day', 'month'], how='left')\n",
    "\n",
    "    max_humid = (\n",
    "        pd.pivot_table(\n",
    "            data,\n",
    "            values='humidity',\n",
    "            index=['building_number', 'day', 'month'],\n",
    "            aggfunc='max'\n",
    "        )\n",
    "        .reset_index()\n",
    "        .rename(columns={'humidity': 'max_humid'})\n",
    "    )\n",
    "    data = pd.merge(data, max_humid, on=['building_number', 'day', 'month'], how='left')\n",
    "\n",
    "    min_humid = (\n",
    "        pd.pivot_table(\n",
    "            data,\n",
    "            values='humidity',\n",
    "            index=['building_number', 'day', 'month'],\n",
    "            aggfunc='min'\n",
    "        )\n",
    "        .reset_index()\n",
    "        .rename(columns={'humidity': 'min_humid'})\n",
    "    )\n",
    "    data = pd.merge(data, min_humid, on=['building_number', 'day', 'month'], how='left')\n",
    "\n",
    "    data['humid_diff'] = data['max_humid'] - data['min_humid']\n",
    "    return data\n",
    "\n",
    "############################ Target FE  ############################\n",
    "\n",
    "def _prep(df, time_col, group_col):\n",
    "    \"\"\"정렬 헬퍼\"\"\"\n",
    "    return df.sort_values([group_col, time_col])\n",
    "\n",
    "\n",
    "def add_weekly_slope(df: pd.DataFrame,\n",
    "                     time_col: str = 'date_time',\n",
    "                     group_col: str = 'building_number',\n",
    "                     power_col: str = 'power_consumption',\n",
    "                     lookback: int = 6) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    1주일 전 최근 lookback 시간의 선형회귀 기울기(β) 피처 추가\n",
    "    \"\"\"\n",
    "    df = _prep(df, time_col, group_col)\n",
    "\n",
    "    def _beta(x: pd.Series) -> float:\n",
    "        if x.isna().any(): return np.nan\n",
    "        idx = np.arange(len(x))\n",
    "        num = idx.dot(x) * len(x) - idx.sum() * x.sum()\n",
    "        den = len(x) * (idx**2).sum() - idx.sum()**2\n",
    "        return num / den if den else 0.0\n",
    "\n",
    "    pw_seq = df.groupby(group_col)[power_col].shift(WEEK_H)\n",
    "    col = f'power_week_slope{lookback}h'\n",
    "    df[col] = pw_seq.groupby(df[group_col]).transform(\n",
    "        lambda s: s.rolling(lookback).apply(_beta, raw=False)\n",
    "    ).fillna(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "############################ Time FE  ############################\n",
    "def irregular_holidays_map():\n",
    "    return {\n",
    "        # --- Research Institute (기본: 주말·공휴일 휴식) ---\n",
    "        23: {\"pattern\": [(\"weekday_nth_in_month\", {\"weekday\": 4, \"nth\": [3]})],  # 금요일 3번째\n",
    "             \"dates\": [\"2024-06-07\", \"2024-08-16\"]},\n",
    "        49: {\"dates\": [\"2024-08-22\"]},\n",
    "        53: {\"dates\": [\"2024-06-15\", \"2024-06-16\"]},\n",
    "        94: {\"dates\": [\"2024-06-07\", \"2024-08-16\"]},\n",
    "\n",
    "        # --- IDC ---\n",
    "        # 67: 기본은 주말만, 단 8/15는 예외적으로 쉼(불규칙)\n",
    "        67: {\"dates\": [\"2024-08-15\"]},\n",
    "\n",
    "        # --- Other (건물기타) ---\n",
    "        26: {\"pattern\": [(\"weekday_every_week\", {\"weekdays\": [0, 1]})]},  # 월/화 휴일\n",
    "        82: {\"pattern\": [(\"weekday_every_week\", {\"weekdays\": [0]})]},     # 월 휴일\n",
    "        97: {\"pattern\": [(\"weekday_every_week\", {\"weekdays\": [5]})]},     # 토 휴일\n",
    "        # 47, 69는 '주말·공휴일 휴식'이 기본이므로 불규칙 아님\n",
    "\n",
    "        # --- Department Store (기본: 공휴일에도 영업) ---\n",
    "        18: {\"pattern\": [(\"weekday_every_week\", {\"weekdays\": [6]})]},     # 매주 일\n",
    "        27: {\"pattern\": [(\"weekday_nth_in_month\", {\"weekday\": 6, \"nth\": [2, 4]})]},\n",
    "        29: {\"pattern\": [(\"weekday_nth_in_month\", {\"weekday\": 6, \"nth\": [4]})],\n",
    "             \"dates\": [\"2024-06-10\", \"2024-07-10\", \"2024-08-10\"]},\n",
    "        32: {\"pattern\": [(\"weekday_nth_in_month\", {\"weekday\": 0, \"nth\": [2, 4]})]},  # 월\n",
    "        40: {\"pattern\": [(\"weekday_nth_in_month\", {\"weekday\": 6, \"nth\": [2, 4]})]},\n",
    "        59: {\"pattern\": [(\"weekday_nth_in_month\", {\"weekday\": 6, \"nth\": [2, 4]})]},\n",
    "        63: {\"pattern\": [(\"weekday_nth_in_month\", {\"weekday\": 6, \"nth\": [2, 4]})]},\n",
    "        19: {\"dates\": [\"2024-06-10\", \"2024-07-08\", \"2024-08-19\"]},\n",
    "        45: {\"dates\": [\"2024-06-10\", \"2024-07-08\", \"2024-08-19\"]},\n",
    "        54: {\"dates\": [\"2024-06-17\", \"2024-07-01\", \"2024-08-19\"]},\n",
    "        74: {\"dates\": [\"2024-06-17\", \"2024-07-01\"]},\n",
    "        79: {\"dates\": [\"2024-06-17\", \"2024-07-01\", \"2024-08-19\"]},\n",
    "        95: {\"dates\": [\"2024-07-08\", \"2024-08-05\"]},\n",
    "\n",
    "        # 참고: 다음은 '불규칙 없음/항상 영업' 메모(휴일 목록은 비우거나 생략)\n",
    "        34: {\"no_extra\": True}, 73: {\"no_extra\": True}, 88: {\"no_extra\": True},  # Dept. no extra\n",
    "        33: {\"always_open\": True}, 92: {\"always_open\": True},  # Public 예외(항상 영업)\n",
    "        # Apartment/Hotel은 기본적으로 항상 영업(불규칙 없음)\n",
    "    }\n",
    "\n",
    "def mean_std_power(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    - dow_hour_mean/std 계산 시:\n",
    "      1) 모든 건물의 2024-06-06, 2024-08-15 제외\n",
    "      2) irregular_holidays_map() 의 'dates' 로 지정된 불규칙 휴일만 제외\n",
    "         (weekday_every_week / weekday_nth_in_month 패턴은 제외하지 않음)\n",
    "    - 다른 통계는 기존과 동일하게 계산\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    is_train = df['power_consumption'].notna()\n",
    "\n",
    "    # === 시간 파생 보강 ===\n",
    "    dt = pd.to_datetime(df['date_time'])\n",
    "    if 'date' not in df.columns:\n",
    "        df['date'] = dt.dt.date\n",
    "    if 'hour' not in df.columns:\n",
    "        df['hour'] = dt.dt.hour\n",
    "    if 'day_of_week' not in df.columns:\n",
    "        df['day_of_week'] = dt.dt.weekday  # 0=Mon..6=Sun\n",
    "    if 'month' not in df.columns:\n",
    "        df['month'] = dt.dt.month\n",
    "\n",
    "    # holiday 플래그 처리(입력 신뢰)\n",
    "    df['holiday'] = df['holiday'].fillna(0).astype(int)\n",
    "\n",
    "    # === (원 코드 유지) 요일별 스케일링 보정 ===\n",
    "    base_ratio = np.array([1.0] * 7)   # 월~일 모두 1\n",
    "    ratio_all = base_ratio - 0\n",
    "    df.loc[is_train, 'power_consumption'] = df.loc[is_train].apply(\n",
    "        lambda r: r['power_consumption'] * ratio_all[int(r['day_of_week'])],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    train_df = df[is_train].copy()\n",
    "\n",
    "    # ============================================================\n",
    "    # 3-A) 요일·시간별 평균/표준편차 (요구 사항에 따른 '제외' 적용)\n",
    "    # ============================================================\n",
    "    # 1) 공휴일(6/6, 8/15) 전건물 제외\n",
    "    PUBLIC_HOLS = {\"2024-06-06\", \"2024-08-15\"}\n",
    "    train_df_dow = train_df[~train_df['date'].astype(str).isin(PUBLIC_HOLS)].copy()\n",
    "\n",
    "    # 2) 불규칙 휴일(단, dates만 제외. 패턴은 포함)\n",
    "    try:\n",
    "        irr = irregular_holidays_map()\n",
    "    except NameError:\n",
    "        irr = {}\n",
    "\n",
    "    # 빌딩별 'dates' 집합 사전\n",
    "    irr_dates_by_bn = {\n",
    "        bn: set(info.get(\"dates\", []))\n",
    "        for bn, info in irr.items()\n",
    "        if isinstance(info, dict) and \"dates\" in info and info[\"dates\"]\n",
    "    }\n",
    "    # dates 기준 제외 마스크 구성\n",
    "    if irr_dates_by_bn:\n",
    "        bnum = train_df_dow[\"building_number\"].to_numpy()\n",
    "        date_str = train_df_dow[\"date\"].astype(str).to_numpy()\n",
    "        exclude_mask = np.zeros(len(train_df_dow), dtype=bool)\n",
    "        for bn, dset in irr_dates_by_bn.items():\n",
    "            if not dset:\n",
    "                continue\n",
    "            exclude_mask |= (bnum == bn) & np.isin(date_str, list(dset))\n",
    "        train_df_dow = train_df_dow.loc[~exclude_mask].copy()\n",
    "\n",
    "    # (주의) weekday_every_week / weekday_nth_in_month 패턴은 '제외하지 않음'\n",
    "\n",
    "    # 그룹 통계\n",
    "    dow_hour_mean = (\n",
    "        train_df_dow\n",
    "        .groupby(['building_number', 'hour', 'day_of_week'])['power_consumption']\n",
    "        .mean()\n",
    "        .reset_index(name='dow_hour_mean')\n",
    "    )\n",
    "    dow_hour_std = (\n",
    "        train_df_dow\n",
    "        .groupby(['building_number', 'hour', 'day_of_week'])['power_consumption']\n",
    "        .std()\n",
    "        .reset_index(name='dow_hour_std')\n",
    "    )\n",
    "    df = df.merge(dow_hour_mean, on=['building_number', 'hour', 'day_of_week'], how='left')\n",
    "    df = df.merge(dow_hour_std,  on=['building_number', 'hour', 'day_of_week'], how='left')\n",
    "\n",
    "    # ============================================================\n",
    "    # 3-B) holiday_mean & holiday_std (원 로직 유지)\n",
    "    # ============================================================\n",
    "    hol_mean = (\n",
    "        train_df\n",
    "        .groupby(['building_number', 'hour', 'holiday'])['power_consumption']\n",
    "        .mean()\n",
    "        .reset_index(name='holiday_mean')\n",
    "    )\n",
    "    hol_std = (\n",
    "        train_df\n",
    "        .groupby(['building_number', 'hour', 'holiday'])['power_consumption']\n",
    "        .std()\n",
    "        .reset_index(name='holiday_std')\n",
    "    )\n",
    "    df = df.merge(hol_mean, on=['building_number', 'hour', 'holiday'], how='left')\n",
    "    df = df.merge(hol_std,  on=['building_number', 'hour', 'holiday'], how='left')\n",
    "\n",
    "    # ============================================================\n",
    "    # 3-C) 시간(hour)별 평균·표준편차 (원 로직 유지)\n",
    "    # ============================================================\n",
    "    hr_mean = (\n",
    "        train_df\n",
    "        .groupby(['building_number', 'hour'])['power_consumption']\n",
    "        .mean()\n",
    "        .reset_index(name='hour_mean')\n",
    "    )\n",
    "    hr_std = (\n",
    "        train_df\n",
    "        .groupby(['building_number', 'hour'])['power_consumption']\n",
    "        .std()\n",
    "        .reset_index(name='hour_std')\n",
    "    )\n",
    "    df = df.merge(hr_mean, on=['building_number', 'hour'], how='left')\n",
    "    df = df.merge(hr_std,  on=['building_number', 'hour'], how='left')\n",
    "\n",
    "    # ============================================================\n",
    "    # 3-D) month·hour별 평균·표준편차 (원 로직 유지)\n",
    "    # ============================================================\n",
    "    mh_mean = (\n",
    "        train_df\n",
    "        .groupby(['building_number', 'month', 'hour'])['power_consumption']\n",
    "        .mean()\n",
    "        .reset_index(name='month_hour_mean')\n",
    "    )\n",
    "    mh_std = (\n",
    "        train_df\n",
    "        .groupby(['building_number', 'month', 'hour'])['power_consumption']\n",
    "        .std()\n",
    "        .reset_index(name='month_hour_std')\n",
    "    )\n",
    "    df = df.merge(mh_mean, on=['building_number', 'month', 'hour'], how='left')\n",
    "    df = df.merge(mh_std,  on=['building_number', 'month', 'hour'], how='left')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62677f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "KR_HOLIDAYS_2024 = {\"2024-06-06\", \"2024-08-15\"}\n",
    "def _ensure_dt(df):\n",
    "    if not np.issubdtype(df[\"date_time\"].dtype, np.datetime64):\n",
    "        df[\"date_time\"] = pd.to_datetime(df[\"date_time\"])\n",
    "    return df\n",
    "\n",
    "def _nth_weekday_in_month(series_dt, weekday_target):\n",
    "    # 월 내 해당 요일의 n번째 (1=첫째, 2=둘째, ...)\n",
    "    first_of_month = series_dt.values.astype(\"datetime64[M]\").astype(\"datetime64[ns]\")\n",
    "    first_weekday = pd.to_datetime(first_of_month).weekday\n",
    "    weekday = series_dt.dt.weekday.values\n",
    "    day = series_dt.dt.day.values\n",
    "    first_occ_day = 1 + ((weekday_target - first_weekday) % 7)\n",
    "    nth = ((day - first_occ_day) // 7) + 1\n",
    "    nth = np.where(day >= first_occ_day, nth, 0)\n",
    "    return nth\n",
    "\n",
    "def add_holiday(df: pd.DataFrame, kr_holidays: set[str] = None) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    _ensure_dt(df)\n",
    "    if kr_holidays is None:\n",
    "        kr_holidays = KR_HOLIDAYS_2024\n",
    "\n",
    "    # 기본 파생 (is_weekend은 '계산만' 하고 이후 어떤 건물에도 수정하지 않음)\n",
    "    df[\"weekday\"] = df[\"date_time\"].dt.weekday          # 0=Mon..6=Sun\n",
    "    df[\"date\"]    = df[\"date_time\"].dt.date\n",
    "    df[\"is_weekend\"] = (df[\"weekday\"] >= 5).astype(int) # 그대로 유지\n",
    "    df[\"holiday\"] = 0\n",
    "\n",
    "    # 공휴일 여부는 컬럼으로 저장하지 않고, 로컬 불리언으로만 사용\n",
    "    is_kr = df[\"date\"].astype(str).isin(kr_holidays).values\n",
    "\n",
    "    bt = df[\"building_type\"]\n",
    "\n",
    "    # ── Apartment: 항상 영업\n",
    "    mm = bt == \"Apartment\"\n",
    "    df.loc[mm, \"holiday\"] = 0\n",
    "\n",
    "    # ── Hospital: 주말 or 공휴일 휴식\n",
    "    mm = bt == \"Hospital\"\n",
    "    if mm.any():\n",
    "        df.loc[mm, \"holiday\"] = (df.loc[mm, \"is_weekend\"].values | is_kr[mm]).astype(int)\n",
    "\n",
    "    # ── Public: 기본 주말 or 공휴일 휴식, 단 33/92는 항상 영업\n",
    "    mm = bt == \"Public\"\n",
    "    if mm.any():\n",
    "        df.loc[mm, \"holiday\"] = (df.loc[mm, \"is_weekend\"].values | is_kr[mm]).astype(int)\n",
    "        mm_always_open = df[\"building_number\"].isin([33, 92])\n",
    "        df.loc[mm_always_open, \"holiday\"] = 0\n",
    "\n",
    "    # ── Hotel: 항상 영업\n",
    "    mm = bt == \"Hotel\"\n",
    "    df.loc[mm, \"holiday\"] = 0\n",
    "\n",
    "    # ── School: 주말 or 공휴일 휴식\n",
    "    mm = bt == \"School\"\n",
    "    if mm.any():\n",
    "        df.loc[mm, \"holiday\"] = (df.loc[mm, \"is_weekend\"].values | is_kr[mm]).astype(int)\n",
    "\n",
    "    # ── IDC(전화국): 개별 규칙\n",
    "    mm_idc = bt == \"IDC\"\n",
    "    if mm_idc.any():\n",
    "        # 36,43,52: 주말 or 공휴일\n",
    "        ids = [36, 43, 52]\n",
    "        mmx = df[\"building_number\"].isin(ids)\n",
    "        df.loc[mmx, \"holiday\"] = (df.loc[mmx, \"is_weekend\"].values | is_kr[mmx]).astype(int)\n",
    "        # 64: 주말만\n",
    "        mmx = df[\"building_number\"].eq(64)\n",
    "        df.loc[mmx, \"holiday\"] = df.loc[mmx, \"is_weekend\"].astype(int)\n",
    "        # 67: 주말 + 8/15\n",
    "        mmx = df[\"building_number\"].eq(67)\n",
    "        if mmx.any():\n",
    "            df.loc[mmx, \"holiday\"] = df.loc[mmx, \"is_weekend\"].astype(int)\n",
    "            df.loc[mmx & (df[\"date\"].astype(str) == \"2024-08-15\"), \"holiday\"] = 1\n",
    "        # 30,35,57: 휴일 없음 → holiday=0 유지\n",
    "\n",
    "    # ── Commercial: 개별 규칙\n",
    "    mm = bt == \"Commercial\"\n",
    "    if mm.any():\n",
    "        # 2: 주말만\n",
    "        mmx = df[\"building_number\"].eq(2)\n",
    "        df.loc[mmx, \"holiday\"] = df.loc[mmx, \"is_weekend\"].astype(int)\n",
    "        # 6,16,20,51,86: 주말 or 공휴일\n",
    "        ids = [6, 16, 20, 51, 86]\n",
    "        mmx = df[\"building_number\"].isin(ids)\n",
    "        df.loc[mmx, \"holiday\"] = (df.loc[mmx, \"is_weekend\"].values | is_kr[mmx]).astype(int)\n",
    "        # 41,56,76,99: 휴일 없음 → holiday=0 유지\n",
    "\n",
    "    # ── Other Buildings: 개별 규칙\n",
    "    # 26: 월/화\n",
    "    mmx = df[\"building_number\"].eq(26)\n",
    "    df.loc[mmx, \"holiday\"] = df.loc[mmx, \"weekday\"].isin([0, 1]).astype(int)\n",
    "    # 82: 월\n",
    "    mmx = df[\"building_number\"].eq(82)\n",
    "    df.loc[mmx, \"holiday\"] = df.loc[mmx, \"weekday\"].eq(0).astype(int)\n",
    "    # 47,69: 주말 or 공휴일\n",
    "    mmx = df[\"building_number\"].isin([47, 69])\n",
    "    df.loc[mmx, \"holiday\"] = (df.loc[mmx, \"is_weekend\"].values | is_kr[mmx]).astype(int)\n",
    "    # 58,61,78: 주말에도 영업 → holiday=0 유지 (is_weekend는 건드리지 않음)\n",
    "    # 97: 토요일만\n",
    "    mmx = df[\"building_number\"].eq(97)\n",
    "    df.loc[mmx, \"holiday\"] = df.loc[mmx, \"weekday\"].eq(5).astype(int)\n",
    "\n",
    "    # ── Department Store: 공휴일에도 영업. 개별 규칙만 휴일 처리.\n",
    "    mm = bt == \"Department Store\"\n",
    "    if mm.any():\n",
    "        df.loc[mm, \"holiday\"] = 0\n",
    "\n",
    "        nth_sun = _nth_weekday_in_month(df[\"date_time\"], 6)  # Sun\n",
    "        nth_mon = _nth_weekday_in_month(df[\"date_time\"], 0)  # Mon\n",
    "\n",
    "        def mark_nth_weekday(building, weekday, nth_set):\n",
    "            if weekday == 6:\n",
    "                nth = nth_sun\n",
    "            elif weekday == 0:\n",
    "                nth = nth_mon\n",
    "            else:\n",
    "                nth = _nth_weekday_in_month(df[\"date_time\"], weekday)\n",
    "            sel = df[\"building_number\"].eq(building) & df[\"weekday\"].eq(weekday) & pd.Series(nth).isin(list(nth_set)).values\n",
    "            df.loc[sel, \"holiday\"] = 1\n",
    "\n",
    "        # 매주/격주/특정일\n",
    "        df.loc[df[\"building_number\"].eq(18) & df[\"weekday\"].eq(6), \"holiday\"] = 1  # 18: 매주 일요일\n",
    "\n",
    "        special = {\n",
    "            19: [\"2024-06-10\", \"2024-07-08\", \"2024-08-19\"],\n",
    "            45: [\"2024-06-10\", \"2024-07-08\", \"2024-08-19\"],\n",
    "            54: [\"2024-06-17\", \"2024-07-01\", \"2024-08-19\"],\n",
    "            74: [\"2024-06-17\", \"2024-07-01\"],\n",
    "            79: [\"2024-06-17\", \"2024-07-01\", \"2024-08-19\"],\n",
    "            95: [\"2024-07-08\", \"2024-08-05\"],\n",
    "            29: [\"2024-06-10\", \"2024-07-10\", \"2024-08-10\"],\n",
    "        }\n",
    "        for b, dates in special.items():\n",
    "            sel = df[\"building_number\"].eq(b) & df[\"date\"].astype(str).isin(dates)\n",
    "            df.loc[sel, \"holiday\"] = 1\n",
    "\n",
    "        # 격주 규칙\n",
    "        mark_nth_weekday(27, 6, {2, 4})  # 27: 2·4번째 일요일\n",
    "        mark_nth_weekday(29, 6, {4})     # 29: 4번째 일요일\n",
    "        mark_nth_weekday(32, 0, {2, 4})  # 32: 2·4번째 월요일\n",
    "        for b in [40, 59, 63]:           # 2·4번째 일요일\n",
    "            mark_nth_weekday(b, 6, {2, 4})\n",
    "\n",
    "        # 34,73,88: 휴일 없음 → holiday=0 유지\n",
    "\n",
    "    mm = bt == \"Research Institute\"\n",
    "    if mm.any():\n",
    "        # 기본: 주말 또는 KR 공휴일이면 휴일\n",
    "        df.loc[mm, \"holiday\"] = (df.loc[mm, \"is_weekend\"].values | is_kr[mm]).astype(int)\n",
    "\n",
    "        # ===== 개별 규칙 =====\n",
    "        # 23번: 매달 '3번째 금요일' + 지정일(6/7, 8/16) 추가 휴일\n",
    "        nth_fri = _nth_weekday_in_month(df[\"date_time\"], 4)  # 4=Friday (0=Mon)\n",
    "        sel_23 = df[\"building_number\"].eq(23) & mm\n",
    "        # 매달 3번째 금요일\n",
    "        df.loc[sel_23 & df[\"weekday\"].eq(4) & pd.Series(nth_fri).eq(3).values, \"holiday\"] = 1\n",
    "        # 추가 지정일\n",
    "        extra_23 = {\"2024-06-07\", \"2024-08-16\"}\n",
    "        df.loc[sel_23 & df[\"date\"].astype(str).isin(extra_23), \"holiday\"] = 1\n",
    "\n",
    "        # 49번: 8/22 휴일 (불규칙 → 하드코딩)\n",
    "        sel_49 = df[\"building_number\"].eq(49) & mm\n",
    "        df.loc[sel_49 & df[\"date\"].astype(str).eq(\"2024-08-22\"), \"holiday\"] = 1\n",
    "\n",
    "        # 53번: 6/15, 6/16 임시 휴일 (불규칙 → 하드코딩)\n",
    "        sel_53 = df[\"building_number\"].eq(53) & mm\n",
    "        extra_53 = {\"2024-06-15\", \"2024-06-16\"}\n",
    "        df.loc[sel_53 & df[\"date\"].astype(str).isin(extra_53), \"holiday\"] = 1\n",
    "\n",
    "        # 94번: 6/7, 8/16 자체 휴일 (불규칙 → 하드코딩)\n",
    "        sel_94 = df[\"building_number\"].eq(94) & mm\n",
    "        extra_94 = {\"2024-06-07\", \"2024-08-16\"}\n",
    "        df.loc[sel_94 & df[\"date\"].astype(str).isin(extra_94), \"holiday\"] = 1\n",
    "    # 안전 재확인: IDC 67의 8/15\n",
    "    df.loc[(df[\"building_number\"].eq(67)) & (df[\"date\"].astype(str) == \"2024-08-15\"), \"holiday\"] = 1\n",
    "\n",
    "    return df\n",
    "\n",
    "def remove_outliers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    _ensure_dt(df)\n",
    "\n",
    "    rules_lt = [\n",
    "        # (building_number, threshold)\n",
    "        # Apartment\n",
    "        (25, 0, \"eq\"), (70, 200, \"lt\"),\n",
    "        # Hospital\n",
    "        (44, 800, \"lt\"), (90, 800, \"lt\"), (42, 2000, \"lt\"), (17, 1000, \"lt\"),\n",
    "        # Public\n",
    "        (68, 600, \"lt\"), (72, 600, \"lt\"), (80, 600, \"lt\"), (92, 200, \"lt\"),\n",
    "        # Hotel\n",
    "        (98, 500, \"lt\"),\n",
    "        # Other\n",
    "        (97, 500, \"lt\"), (78, 400, \"lt\"), (26, 300, \"lt\"), (7, 2000, \"lt\"),\n",
    "        # Commercial\n",
    "        (76, 2000, \"lt\"), (41, 2200, \"lt\"), (20, 1600, \"lt\"),\n",
    "        # School\n",
    "        (5, 2000, \"lt\"), (8, 250, \"lt\"), (12, 3500, \"lt\"),\n",
    "        # IDC\n",
    "        (67, 7333, \"lt\"), (81, 800, \"lt\"), (52, 2000, \"lt\"), (43, 6000, \"lt\"), (30, 8000, \"lt\"),\n",
    "    ]\n",
    "\n",
    "    # 값 기반 제거\n",
    "    mask_ok = pd.Series(True, index=df.index)\n",
    "    pc = df[\"power_consumption\"]\n",
    "    bnum = df[\"building_number\"]\n",
    "\n",
    "    for bn, th, op in rules_lt:\n",
    "        if op == \"lt\":\n",
    "            mask_ok &= ~((bnum.eq(bn)) & (pc < th))\n",
    "        elif op == \"eq\":\n",
    "            mask_ok &= ~((bnum.eq(bn)) & (pc == th))\n",
    "\n",
    "    # 기간 기반 제거\n",
    "    # Hotel 10: 2024-07-05 ~ 2024-08-22\n",
    "    mask_ok &= ~(\n",
    "        (bnum.eq(10)) &\n",
    "        (df[\"date_time\"].between(pd.Timestamp(\"2024-07-05\"), pd.Timestamp(\"2024-08-22\")))\n",
    "    )\n",
    "    # IDC 57: 2024-06-07 이전\n",
    "    mask_ok &= ~(\n",
    "        (bnum.eq(57)) & (df[\"date_time\"] < pd.Timestamp(\"2024-06-07\"))\n",
    "    )\n",
    "    # Research 94: 2024-07-27 09:00 ~ 2024-08-04 23:00\n",
    "    mask_ok &= ~(\n",
    "        (bnum.eq(94)) &\n",
    "        (df[\"date_time\"].between(pd.Timestamp(\"2024-07-27 09:00\"), pd.Timestamp(\"2024-08-04 23:00\")))\n",
    "    )\n",
    "\n",
    "    # === 추가 규칙: Research 53 ===\n",
    "    # 1) 2024-06-15, 2024-06-16 전체 제거 (통짜 이상치)\n",
    "    mask_ok &= ~(\n",
    "        (bnum.eq(53)) &\n",
    "        (df[\"date_time\"].dt.normalize().isin([pd.Timestamp(\"2024-06-15\"),\n",
    "                                              pd.Timestamp(\"2024-06-16\")]))\n",
    "    )\n",
    "    # 2) 2024-08-17 이후에서 power_consumption <= 1000 제거\n",
    "    mask_ok &= ~(\n",
    "        (bnum.eq(53)) &\n",
    "        (df[\"date_time\"] >= pd.Timestamp(\"2024-08-17\")) &\n",
    "        (pc <= 1000)\n",
    "    )\n",
    "\n",
    "    return df.loc[mask_ok].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49b5966",
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP_COLS = ['sunshine','solar_radiation', 'solar_power_capacity','ess_capacity', 'pcs_capacity', \n",
    "             'hour', 'day_of_week', 'day_of_year']\n",
    "CAT_COLS = ['building_type', 'building_number']\n",
    "GROUP_COLS =  [\"building_number\",\"hour\",\"day_of_week\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50000705",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_and_process(\"./data\")\n",
    "train, test = create_datetime(train), create_datetime(test)\n",
    "combined_df = pd.concat([train, test], ignore_index=True)\n",
    "combined_df = add_holiday(combined_df) \n",
    "combined_df = remove_outliers(combined_df)\n",
    "combined_df = add_squared_features(combined_df)\n",
    "combined_df = add_summer_cycle_features(combined_df)\n",
    "combined_df = create_cyclic_features(combined_df)\n",
    "comgined_df = add_cdh_feature(combined_df)\n",
    "combined_df = add_cdd_feature(combined_df)\n",
    "combined_df = add_thi_feature(combined_df)\n",
    "combined_df = add_wct_feature(combined_df)\n",
    "combined_df = add_temp_features(combined_df)\n",
    "combined_df = add_humid_features(combined_df)\n",
    "combined_df = mean_std_power(combined_df)\n",
    "combined_df = add_weekly_slope(combined_df)\n",
    "\n",
    "split_date = pd.to_datetime('2024-08-25 00:00:00')\n",
    "val_date   = split_date - pd.Timedelta(days=7)\n",
    "\n",
    "x_full_train = combined_df[combined_df['date_time'] < split_date].copy()\n",
    "x_train = combined_df[combined_df['date_time'] < val_date].copy()\n",
    "x_val   = combined_df[(combined_df['date_time'] >= val_date) & (combined_df['date_time'] < split_date)].copy()\n",
    "test  = combined_df[combined_df['date_time'] >= split_date].copy()\n",
    "for c in CAT_COLS:\n",
    "    x_train[c] = x_train[c].astype('category')\n",
    "    x_full_train[c] = x_full_train[c].astype('category')\n",
    "    x_val[c]   = x_val[c].astype('category')\n",
    "    test[c]  = test[c].astype('category')\n",
    "\n",
    "x_full_train = x_full_train.ffill() \n",
    "x_train = x_train.ffill() \n",
    "x_val = x_val.ffill() \n",
    "\n",
    "x_full_train.drop(columns=DROP_COLS, inplace=True)\n",
    "x_train.drop(columns=DROP_COLS, inplace=True)\n",
    "x_val.drop(columns=DROP_COLS, inplace=True)\n",
    "test.drop(columns=DROP_COLS, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de12fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COL_DROP = ['date','date_time','hour_mean','humidity_squared']\n",
    "COL_DROP = ['date','date_time']\n",
    "TARGET = 'power_consumption'\n",
    "SEED = 42 \n",
    "# 피처 / 타겟 분리\n",
    "X_train = x_train.drop(columns=COL_DROP + [TARGET], errors='ignore')\n",
    "y_train = x_train[TARGET]\n",
    "X_val = x_val.drop(columns=COL_DROP + [TARGET], errors='ignore')\n",
    "y_val = x_val[TARGET]\n",
    "X_test = test.drop(columns=COL_DROP+[TARGET], errors='ignore')\n",
    "X_full = x_full_train.drop(columns=COL_DROP + [TARGET], errors='ignore')\n",
    "y_full = x_full_train[TARGET]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbd758f",
   "metadata": {},
   "source": [
    "## Train & Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b342b5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_by_building_type(\n",
    "    X_full, y_full, X_test,is_base, \n",
    "    seed=42,\n",
    "    n_estimators=16,\n",
    "    max_depth=5,\n",
    "    min_samples_split=100,\n",
    "    min_samples_leaf=10,\n",
    "    max_predict_time=60,\n",
    "    verbose=1,\n",
    "    show_progress=True, \n",
    "):\n",
    "    \"\"\"\n",
    "    building_type별로 TabPFN 기반 RandomForest 학습 후\n",
    "    X_test 예측 결과 반환\n",
    "\n",
    "    Args:\n",
    "        X_full, y_full: 전체 학습 데이터\n",
    "        X_test: 테스트 데이터\n",
    "        (이외 파라미터는 모델 하이퍼파라미터)\n",
    "\n",
    "    Returns:\n",
    "        test_preds: {building_type: 예측 np.array}\n",
    "        preds_all:  X_test.index 순서대로 정렬된 전체 예측(pd.Series)\n",
    "    \"\"\"\n",
    "    preds_all = pd.Series(index=X_test.index, dtype=float)\n",
    "    preds_by_type = {}\n",
    "\n",
    "    for btype in X_full[\"building_type\"].unique():\n",
    "        print(f\"\\n▶ Building type: {btype}\")\n",
    "\n",
    "        # building_type 제거 후 데이터 분리\n",
    "        tr_idx = X_full[\"building_type\"] == btype\n",
    "        te_idx = X_test[\"building_type\"] == btype\n",
    "\n",
    "        Xtr = X_full.loc[tr_idx].drop(columns=[\"building_type\"])\n",
    "        ytr = y_full.loc[tr_idx]\n",
    "        Xte = X_test.loc[te_idx].drop(columns=[\"building_type\"])\n",
    "\n",
    "        # TabPFN 베이스 모델 (GPU)\n",
    "        reg_base = TabPFNRegressor(\n",
    "            device=\"cuda\",\n",
    "            ignore_pretraining_limits=True,\n",
    "            random_state=seed\n",
    "        )\n",
    "\n",
    "        model = RandomForestTabPFNRegressor(\n",
    "            tabpfn=reg_base,\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            #min_samples_split=min_samples_split,\n",
    "            #min_samples_leaf=min_samples_leaf,\n",
    "            show_progress=show_progress,\n",
    "            verbose=verbose,\n",
    "            max_predict_time=max_predict_time,\n",
    "        )\n",
    "        basemodel = RandomForestTabPFNRegressor(\n",
    "            tabpfn=reg_base,\n",
    "            show_progress=show_progress,\n",
    "            verbose=verbose,\n",
    "            max_predict_time=max_predict_time,\n",
    "        )\n",
    "        if is_base == True :\n",
    "            model = basemodel \n",
    "        # 학습 및 예측\n",
    "        model.fit(Xtr, ytr)\n",
    "        preds = model.predict(Xte)\n",
    "\n",
    "        preds_by_type[btype] = preds\n",
    "        preds_all.loc[te_idx] = preds\n",
    "\n",
    "        print(f\"building_type={btype}, preds shape={preds.shape}\")\n",
    "\n",
    "    return preds_by_type, preds_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f970d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_by_building_type2(\n",
    "    X_full, y_full, X_test, is_base,\n",
    "    seed=42,\n",
    "    n_estimators=16,\n",
    "    max_depth=5,\n",
    "    min_samples_split=100,\n",
    "    min_samples_leaf=10,\n",
    "    max_predict_time=60,\n",
    "    verbose=1,\n",
    "    show_progress=True,\n",
    "    categorical_cols=None,   # ['building_number', ...] 등 (building_type 제외)\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    \"\"\"\n",
    "    building_type별로 학습 후 X_test 예측 반환\n",
    "    Returns:\n",
    "        preds_by_type: {btype: np.ndarray}\n",
    "        preds_all: pd.Series (X_test.index 순서)\n",
    "    \"\"\"\n",
    "    preds_all = pd.Series(index=X_test.index, dtype=float)\n",
    "    preds_by_type = {}\n",
    "\n",
    "    # 범주형 인덱스 계산 (building_type은 드롭하므로 제외)\n",
    "    def _cat_idx(df, cat_cols):\n",
    "        if not cat_cols: \n",
    "            return None\n",
    "        cols = [c for c in cat_cols if c in df.columns and c != \"building_type\"]\n",
    "        return [df.columns.get_loc(c) for c in cols]\n",
    "\n",
    "    for btype in X_full[\"building_type\"].unique():\n",
    "        print(f\"\\n▶ Building type: {btype}\")\n",
    "\n",
    "        tr_idx = X_full[\"building_type\"] == btype\n",
    "        te_idx = X_test[\"building_type\"] == btype\n",
    "\n",
    "        # test에 해당 타입이 없으면 스킵\n",
    "        if te_idx.sum() == 0:\n",
    "            print(f\"  (skip) no rows in X_test for type={btype}\")\n",
    "            continue\n",
    "\n",
    "        Xtr = X_full.loc[tr_idx].drop(columns=[\"building_type\"])\n",
    "        ytr = y_full.loc[tr_idx]\n",
    "        Xte = X_test.loc[te_idx].drop(columns=[\"building_type\"])\n",
    "\n",
    "        cat_idx = _cat_idx(Xtr, categorical_cols)\n",
    "\n",
    "        # TabPFN 베이스 (GPU)\n",
    "        reg_base = TabPFNRegressor(\n",
    "            device=device,\n",
    "            ignore_pretraining_limits=True,\n",
    "            random_state=seed\n",
    "        )\n",
    "\n",
    "        # 기본/튜닝 모델 선택\n",
    "        if is_base:\n",
    "            model = RandomForestTabPFNRegressor(\n",
    "                tabpfn=reg_base,\n",
    "                categorical_features=cat_idx,\n",
    "                show_progress=show_progress,\n",
    "                verbose=verbose,\n",
    "                max_predict_time=max_predict_time,\n",
    "                n_jobs=-1,\n",
    "                random_state=seed\n",
    "            )\n",
    "        else:\n",
    "            model = RandomForestTabPFNRegressor(\n",
    "                tabpfn=reg_base,\n",
    "                n_estimators=n_estimators,\n",
    "                max_depth=max_depth,\n",
    "                min_samples_split=min_samples_split,\n",
    "                min_samples_leaf=min_samples_leaf,\n",
    "                categorical_features=cat_idx,\n",
    "                show_progress=show_progress,\n",
    "                verbose=verbose,\n",
    "                max_predict_time=max_predict_time,\n",
    "                n_jobs=-1,\n",
    "                random_state=seed\n",
    "            )\n",
    "\n",
    "        # 학습 및 예측\n",
    "        model.fit(Xtr, ytr)\n",
    "        preds = model.predict(Xte)\n",
    "\n",
    "        preds_by_type[btype] = preds\n",
    "        preds_all.loc[te_idx] = preds\n",
    "\n",
    "        print(f\"  preds shape={preds.shape}\")\n",
    "\n",
    "    return preds_by_type, preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "326b82bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Building type: Hotel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimator 0: 100%|██████████| 87/87 [02:02<00:00,  1.41s/it]\n",
      "Estimator 0: 100%|██████████| 87/87 [01:54<00:00,  1.32s/it] \n",
      "Estimator 0: 100%|██████████| 93/93 [02:06<00:00,  1.36s/it] \n",
      "Estimator 0: 100%|██████████| 93/93 [01:49<00:00,  1.18s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building_type=Hotel, preds shape=(1680,)\n",
      "\n",
      "▶ Building type: Commercial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimator 0: 100%|██████████| 67/67 [01:43<00:00,  1.55s/it]\n",
      "Estimator 0: 100%|██████████| 67/67 [01:48<00:00,  1.62s/it]\n",
      "Estimator 0: 100%|██████████| 99/99 [02:22<00:00,  1.44s/it] \n",
      "Estimator 0: 100%|██████████| 99/99 [02:20<00:00,  1.42s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building_type=Commercial, preds shape=(1680,)\n",
      "\n",
      "▶ Building type: Hospital\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimator 0: 100%|██████████| 71/71 [01:48<00:00,  1.52s/it]\n",
      "Estimator 0: 100%|██████████| 71/71 [01:35<00:00,  1.34s/it]\n",
      "Estimator 0: 100%|██████████| 79/79 [01:49<00:00,  1.39s/it]\n",
      "Estimator 0: 100%|██████████| 79/79 [01:41<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building_type=Hospital, preds shape=(1512,)\n",
      "\n",
      "▶ Building type: School\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimator 0: 100%|██████████| 93/93 [02:07<00:00,  1.38s/it] \n",
      "Estimator 0: 100%|██████████| 93/93 [02:15<00:00,  1.46s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building_type=School, preds shape=(1680,)\n",
      "\n",
      "▶ Building type: Other Buildings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimator 0: 100%|██████████| 79/79 [01:42<00:00,  1.29s/it]\n",
      "Estimator 0: 100%|██████████| 79/79 [01:47<00:00,  1.36s/it] \n",
      "Estimator 0: 100%|██████████| 79/79 [01:48<00:00,  1.38s/it]\n",
      "Estimator 0: 100%|██████████| 79/79 [01:48<00:00,  1.38s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building_type=Other Buildings, preds shape=(1680,)\n",
      "\n",
      "▶ Building type: Apartment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimator 0: 100%|██████████| 91/91 [02:03<00:00,  1.36s/it]\n",
      "Estimator 0: 100%|██████████| 91/91 [01:36<00:00,  1.06s/it] \n",
      "Estimator 0: 100%|██████████| 81/81 [01:50<00:00,  1.36s/it]\n",
      "Estimator 0: 100%|██████████| 81/81 [01:36<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building_type=Apartment, preds shape=(1512,)\n",
      "\n",
      "▶ Building type: Research Institute\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimator 0: 100%|██████████| 85/85 [02:05<00:00,  1.47s/it]\n",
      "Estimator 0: 100%|██████████| 85/85 [01:46<00:00,  1.25s/it] \n",
      "Estimator 0: 100%|██████████| 85/85 [01:52<00:00,  1.33s/it]\n",
      "Estimator 0: 100%|██████████| 85/85 [01:30<00:00,  1.06s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building_type=Research Institute, preds shape=(1512,)\n",
      "\n",
      "▶ Building type: Department Store\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimator 0: 100%|██████████| 75/75 [02:31<00:00,  2.02s/it] \n",
      "Estimator 0: 100%|██████████| 75/75 [02:32<00:00,  2.03s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building_type=Department Store, preds shape=(2688,)\n",
      "\n",
      "▶ Building type: IDC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimator 0: 100%|██████████| 89/89 [02:09<00:00,  1.46s/it]\n",
      "Estimator 0: 100%|██████████| 89/89 [01:56<00:00,  1.31s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building_type=IDC, preds shape=(1512,)\n",
      "\n",
      "▶ Building type: Public\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimator 0: 100%|██████████| 83/83 [01:44<00:00,  1.26s/it]\n",
      "Estimator 0: 100%|██████████| 83/83 [01:35<00:00,  1.15s/it]\n",
      "Estimator 0: 100%|██████████| 97/97 [02:02<00:00,  1.27s/it]\n",
      "Estimator 0: 100%|██████████| 97/97 [01:41<00:00,  1.05s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building_type=Public, preds shape=(1344,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "preds_by_type, preds_all = predict_by_building_type(\n",
    "    X_full, y_full, X_test,    seed=SEED,is_base = False, \n",
    "    n_estimators=32,    max_depth=6,    max_predict_time=240,    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6ad397",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('./data/sample_submission.csv')\n",
    "sub['answer'] = preds_all.values\n",
    "sub.to_csv('bytype_pfn.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabpfn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
