{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "617feeb4",
   "metadata": {},
   "source": [
    "## Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee92bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stacking'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, TargetEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tabpfn import TabPFNRegressor\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple, Optional\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser(description=\"stacking\")\n",
    "parser.add_argument('--scaler', default=\"standard\", type=str) # standard or minmax or robust\n",
    "parser.add_argument('--cv', default=10, type=int)\n",
    "parser.add_argument('--seed', default=42, type=int)\n",
    "args = parser.parse_args('')\n",
    "scaler = args.scaler\n",
    "cv = args.cv\n",
    "seed = args.seed\n",
    "\n",
    "if scaler == \"standard\":\n",
    "    scaler = StandardScaler()\n",
    "elif scaler == \"minmax\":\n",
    "    scaler = MinMaxScaler()\n",
    "elif scaler == \"robust\":\n",
    "    scaler = RobustScaler()\n",
    "\n",
    "def set_seeds(seed=seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seeds()\n",
    "\n",
    "idx = f\"{parser.description}\"\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e319f5",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55b96f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 컬럼명 매핑(dict)을 파일 내부에 정의 ──\n",
    "TRAIN_COL_RENAMES = {\n",
    "    '건물번호': 'building_number',\n",
    "    '일시': 'date_time',\n",
    "    '기온(°C)': 'temperature',\n",
    "    '강수량(mm)': 'rainfall',\n",
    "    '풍속(m/s)': 'windspeed',\n",
    "    '습도(%)': 'humidity',\n",
    "    '일조(hr)': 'sunshine',\n",
    "    '일사(MJ/m2)': 'solar_radiation',\n",
    "    '전력소비량(kWh)': 'power_consumption'\n",
    "}\n",
    "TEST_COL_RENAMES = TRAIN_COL_RENAMES.copy()\n",
    "\n",
    "BUILDING_INFO_RENAMES = {\n",
    "    '건물번호': 'building_number',\n",
    "    '건물유형': 'building_type',\n",
    "    '연면적(m2)': 'total_area',\n",
    "    '냉방면적(m2)': 'cooling_area',\n",
    "    '태양광용량(kW)': 'solar_power_capacity',\n",
    "    'ESS저장용량(kWh)': 'ess_capacity',\n",
    "    'PCS용량(kW)': 'pcs_capacity'\n",
    "}\n",
    "TYPE_TRANSLATION = {\n",
    "    '건물기타': 'Other Buildings',\n",
    "    '공공': 'Public',\n",
    "    '학교': 'School',\n",
    "    '백화점': 'Department Store',\n",
    "    '병원': 'Hospital',\n",
    "    '상용': 'Commercial',\n",
    "    '아파트': 'Apartment',\n",
    "    '연구소': 'Research Institute',\n",
    "    '호텔': 'Hotel',\n",
    "    'IDC(전화국)': 'IDC'\n",
    "}\n",
    "\n",
    "def load_raw(data_dir: str = \"../data/raw\"):\n",
    "    train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "    test  = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n",
    "    info  = pd.read_csv(os.path.join(data_dir, 'building_info.csv'))\n",
    "    return train, test, info\n",
    "\n",
    "def rename_columns(df: pd.DataFrame, mapping: dict):\n",
    "    df = df.rename(columns=mapping)\n",
    "    if 'num_date_time' in df.columns:\n",
    "        df = df.drop('num_date_time', axis=1)\n",
    "    return df\n",
    "\n",
    "def preprocess_building_info(info: pd.DataFrame) -> pd.DataFrame:\n",
    "    info = info.rename(columns=BUILDING_INFO_RENAMES)\n",
    "    info['building_type'] = info['building_type'].replace(TYPE_TRANSLATION)\n",
    "    return info\n",
    "\n",
    "def merge_datasets(train: pd.DataFrame, test: pd.DataFrame, info: pd.DataFrame):\n",
    "    train = train.merge(info, on='building_number', how='left')\n",
    "    test  = test.merge(info, on='building_number', how='left')\n",
    "    return train, test\n",
    "\n",
    "def save_processed(df: pd.DataFrame, name: str, out_dir: str = \"../data/processed\"):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    path = os.path.join(out_dir, f\"{name}.pkl\")\n",
    "    df.to_pickle(path)\n",
    "    print(f\"Saved processed data to: {path}\")\n",
    "\n",
    "def load_and_process(data_dir: str = \"../data/raw\") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    1) raw CSV 로드\n",
    "    2) 컬럼명 리네임\n",
    "    3) building_info 전처리 & 병합\n",
    "    4) processed/train.pkl, processed/test.pkl 저장\n",
    "    5) train_df, test_df 반환\n",
    "    \"\"\"\n",
    "    train, test, info = load_raw(data_dir)\n",
    "    train = rename_columns(train, TRAIN_COL_RENAMES)\n",
    "    test  = rename_columns(test, TEST_COL_RENAMES)\n",
    "    info  = preprocess_building_info(info)\n",
    "    train, test = merge_datasets(train, test, info)\n",
    "\n",
    "    save_processed(train, \"train\")\n",
    "    save_processed(test,  \"test\")\n",
    "    return train, test\n",
    "\n",
    "# (Optional) 기존 save → load 편의 함수\n",
    "def load_processed(name: str, proc_dir: str = \"../data/processed\") -> pd.DataFrame:\n",
    "    path = os.path.join(proc_dir, f\"{name}.pkl\")\n",
    "    return pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bf6b628",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEEK_H = 168      # 1주일 = 168시간\n",
    "EPS    = 1e-3     # 0 나눔 방지\n",
    "############################ Base FE ############################\n",
    "\n",
    "def create_datetime(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    date_time 컬럼을 datetime 타입으로 변환하고\n",
    "    시간, 일, 월, 요일, 주말 여부, 연중 일(day_of_year) 피처 및\n",
    "    하루를 4분할하는 시간대(time_of_day) 피처 추가\n",
    "    \"\"\"\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'], format='%Y%m%d %H')\n",
    "    df['hour'] = df['date_time'].dt.hour\n",
    "    df['day'] = df['date_time'].dt.day\n",
    "    df['month'] = df['date_time'].dt.month\n",
    "    df['day_of_week'] = df['date_time'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    df['day_of_year'] = df['date_time'].dt.dayofyear\n",
    "    conditions = [\n",
    "        (df['hour'] >= 0) & (df['hour'] < 6),\n",
    "        (df['hour'] >= 6) & (df['hour'] < 12),\n",
    "        (df['hour'] >= 12) & (df['hour'] < 18),\n",
    "        (df['hour'] >= 18) & (df['hour'] < 24)\n",
    "    ]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def add_summer_cycle_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    여름 기간을 주기로 하는 sin/cos 특성을 생성합니다.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    start_date = datetime.strptime(\"2024-05-20 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "    end_date = datetime.strptime(\"2024-09-08 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "    period_seconds = (end_date - start_date).total_seconds()\n",
    "    \n",
    "    def summer_cos(date):\n",
    "        return np.cos(2 * np.pi * (date - start_date).total_seconds() / period_seconds)\n",
    "    \n",
    "    def summer_sin(date):\n",
    "        return np.sin(2 * np.pi * (date - start_date).total_seconds() / period_seconds)\n",
    "        \n",
    "    df_copy['summer_cos'] = df_copy['date_time'].apply(summer_cos)\n",
    "    df_copy['summer_sin'] = df_copy['date_time'].apply(summer_sin)\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def add_squared_features(\n",
    "    df: pd.DataFrame, \n",
    "    target_cols: List[str] = ['temperature', 'humidity']\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    지정된 컬럼에 대해 제곱(squared) 특성을 생성합니다.\n",
    "    변수가 타겟에 미치는 비선형 관계를 모델이 학습하는 데 도움을 줍니다.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): 특성을 추가할 데이터프레임\n",
    "        target_cols (List[str]): 제곱할 대상 컬럼 리스트\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 제곱 특성이 추가된 데이터프레임\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    for col in target_cols:\n",
    "        df_copy[f'{col}_squared'] = df_copy[col] ** 2\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "def week_cycle_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    if 'day_of_week' not in df.columns:\n",
    "        df['day_of_week'] = pd.to_datetime(df['date_time']).dt.weekday\n",
    "    if 'hour' not in df.columns:\n",
    "        df['hour'] = pd.to_datetime(df['date_time']).dt.hour\n",
    "    how = df['day_of_week'] * 24 + df['hour']\n",
    "    df['sin_how_1'] = np.sin(2 * np.pi * how / 168)\n",
    "    df['cos_how_1'] = np.cos(2 * np.pi * how / 168)\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_cyclic_features(df):\n",
    "    \"\"\"\n",
    "    사이클릭 피처 추가하는 함수 (create_datetime 이후에 사용)\n",
    "    \"\"\"\n",
    "    # hour: 0–23\n",
    "    df['sin_hour'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['cos_hour'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    # (선택) 날짜 전체 주기: day_of_year 1–365 or 366\n",
    "    df['sin_doy'] = np.sin(2 * np.pi * (df['day_of_year'] - 1) / 365)\n",
    "    df['cos_doy'] = np.cos(2 * np.pi * (df['day_of_year'] - 1) / 365)\n",
    "    return df\n",
    "\n",
    "def cooling_degree_hour(temperature, window=12, base_temp=26):\n",
    "    cdhs = []\n",
    "    temps = temperature.values\n",
    "    for i in range(len(temps)):\n",
    "        if i < window:\n",
    "            cdh = np.sum(np.maximum(temps[:i+1] - base_temp, 0))\n",
    "        else:\n",
    "            cdh = np.sum(np.maximum(temps[i-window+1:i+1] - base_temp, 0))\n",
    "        cdhs.append(cdh)\n",
    "    return cdhs\n",
    "\n",
    "\n",
    "def add_cdh_feature(df: pd.DataFrame,\n",
    "                    window: int = 12,\n",
    "                    base_temp: float = 26.0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    건물별 온도 데이터를 이용해 CDH 피처 추가 (cooling_degree_hour 기반)\n",
    "    \"\"\"\n",
    "    cdhs_all = []\n",
    "    for b in df['building_number'].unique():\n",
    "        temps = df.loc[df['building_number'] == b, 'temperature']\n",
    "        cdhs_all.extend(cooling_degree_hour(temps, window=window, base_temp=base_temp))\n",
    "    df['CDH'] = cdhs_all\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_cdd_feature(df: pd.DataFrame,base_temp: float = 18.0,\n",
    "                    window:    int   = 24) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cooling Degree Days (CDD) 추가\n",
    "      - base_temp (°C) 보다 높을 때만 (T - base_temp) 합산\n",
    "      - window 시간 롤링 합산 (min_periods=1)\n",
    "    \"\"\"\n",
    "    # 1) per-hour 초과분 계산\n",
    "    df['excess'] = (df['temperature'] - base_temp).clip(lower=0)\n",
    "    df['CDD'] = (df.groupby('building_number')['excess']                 .transform(lambda s: s.rolling(window, min_periods=1).sum())                )\n",
    "    df.drop(columns=['excess'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def add_thi_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Temperature-Humidity Index (THI) 추가\n",
    "    \"\"\"\n",
    "    df['THI'] = (9/5 * df['temperature'] \n",
    "                 - 0.55 * (1 - df['humidity']/100) \n",
    "                 * (9/5 * df['temperature'] - 26) \n",
    "                 + 32)\n",
    "    return df\n",
    "def add_wct_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Wind Chill Temperature (WCT) 추가\n",
    "    \"\"\"\n",
    "    v16 = df['windspeed'] ** 0.16\n",
    "    df['WCT'] = (13.12 \n",
    "                 + 0.6215 * df['temperature'] \n",
    "                 - 11.37 * v16 \n",
    "                 + 0.3965 * v16 * df['temperature'])\n",
    "    return df\n",
    "\n",
    "def add_temp_features(data):\n",
    "    avg_temp = (\n",
    "        pd.pivot_table(\n",
    "            data[data['hour'] % 3 == 0],\n",
    "            values='temperature',\n",
    "            index=['building_number', 'day', 'month'],\n",
    "            aggfunc='mean'\n",
    "        )\n",
    "        .reset_index()\n",
    "        .rename(columns={'temperature': 'avg_temp'})\n",
    "    )\n",
    "    data = pd.merge(data, avg_temp, on=['building_number', 'day', 'month'], how='left')\n",
    "\n",
    "    max_temp = (\n",
    "        pd.pivot_table(\n",
    "            data,\n",
    "            values='temperature',\n",
    "            index=['building_number', 'day', 'month'],\n",
    "            aggfunc='max'\n",
    "        )\n",
    "        .reset_index()\n",
    "        .rename(columns={'temperature': 'max_temp'})\n",
    "    )\n",
    "    data = pd.merge(data, max_temp, on=['building_number', 'day', 'month'], how='left')\n",
    "\n",
    "    min_temp = (\n",
    "        pd.pivot_table(\n",
    "            data,\n",
    "            values='temperature',\n",
    "            index=['building_number', 'day', 'month'],\n",
    "            aggfunc='min'\n",
    "        )\n",
    "        .reset_index()\n",
    "        .rename(columns={'temperature': 'min_temp'})\n",
    "    )\n",
    "    data = pd.merge(data, min_temp, on=['building_number', 'day', 'month'], how='left')\n",
    "\n",
    "    data['temp_diff'] = data['max_temp'] - data['min_temp']\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def add_humid_features(data):\n",
    "    avg_humid = (\n",
    "        pd.pivot_table(\n",
    "            data[data['hour'] % 3 == 0],\n",
    "            values='humidity',\n",
    "            index=['building_number', 'day', 'month'],\n",
    "            aggfunc='mean'\n",
    "        )\n",
    "        .reset_index()\n",
    "        .rename(columns={'humidity': 'avg_humid'})\n",
    "    )\n",
    "    data = pd.merge(data, avg_humid, on=['building_number', 'day', 'month'], how='left')\n",
    "\n",
    "    max_humid = (\n",
    "        pd.pivot_table(\n",
    "            data,\n",
    "            values='humidity',\n",
    "            index=['building_number', 'day', 'month'],\n",
    "            aggfunc='max'\n",
    "        )\n",
    "        .reset_index()\n",
    "        .rename(columns={'humidity': 'max_humid'})\n",
    "    )\n",
    "    data = pd.merge(data, max_humid, on=['building_number', 'day', 'month'], how='left')\n",
    "\n",
    "    min_humid = (\n",
    "        pd.pivot_table(\n",
    "            data,\n",
    "            values='humidity',\n",
    "            index=['building_number', 'day', 'month'],\n",
    "            aggfunc='min'\n",
    "        )\n",
    "        .reset_index()\n",
    "        .rename(columns={'humidity': 'min_humid'})\n",
    "    )\n",
    "    data = pd.merge(data, min_humid, on=['building_number', 'day', 'month'], how='left')\n",
    "\n",
    "    data['humid_diff'] = data['max_humid'] - data['min_humid']\n",
    "    return data\n",
    "\n",
    "############################ Target FE  ############################\n",
    "\n",
    "def _prep(df, time_col, group_col):\n",
    "    \"\"\"정렬 헬퍼\"\"\"\n",
    "    return df.sort_values([group_col, time_col])\n",
    "\n",
    "def add_weekly_slope(df: pd.DataFrame,\n",
    "                     time_col: str = 'date_time',\n",
    "                     group_col: str = 'building_number',\n",
    "                     power_col: str = 'power_consumption',\n",
    "                     lookback: int = 6) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    1주일 전 최근 lookback 시간의 선형회귀 기울기(β) 피처 추가\n",
    "    \"\"\"\n",
    "    df = _prep(df, time_col, group_col)\n",
    "\n",
    "    def _beta(x: pd.Series) -> float:\n",
    "        if x.isna().any(): return np.nan\n",
    "        idx = np.arange(len(x))\n",
    "        num = idx.dot(x) * len(x) - idx.sum() * x.sum()\n",
    "        den = len(x) * (idx**2).sum() - idx.sum()**2\n",
    "        return num / den if den else 0.0\n",
    "\n",
    "    pw_seq = df.groupby(group_col)[power_col].shift(WEEK_H)\n",
    "    col = f'power_week_slope{lookback}h'\n",
    "    df[col] = pw_seq.groupby(df[group_col]).transform(\n",
    "        lambda s: s.rolling(lookback).apply(_beta, raw=False)\n",
    "    ).fillna(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "############################ Time FE  ############################\n",
    "def mean_std_power(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    is_train = df['power_consumption'].notna()\n",
    "    \n",
    "    # date, hour, day_of_week 컬럼 준비\n",
    "    if 'date' not in df.columns:\n",
    "        df['date'] = pd.to_datetime(df['date_time']).dt.date\n",
    "    if 'hour' not in df.columns:\n",
    "        df['hour'] = pd.to_datetime(df['date_time']).dt.hour\n",
    "    if 'day_of_week' not in df.columns:\n",
    "        df['day_of_week'] = pd.to_datetime(df['date_time']).dt.weekday\n",
    "\n",
    "    # holiday 플래그 처리\n",
    "    df['holiday'] = df['holiday'].fillna(0).astype(int)\n",
    "\n",
    "    # 학습 데이터 비율 조정\n",
    "    base_ratio = np.array([0.985] + [0.98]*2 + [0.995]*2 + [0.99]*2)\n",
    "    ratio_all = base_ratio - 0.005\n",
    "    df.loc[is_train, 'power_consumption'] = df.loc[is_train].apply(\n",
    "        lambda r: r['power_consumption'] * ratio_all[int(r['day_of_week'])],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    train_df = df[is_train]\n",
    "\n",
    "    # 3-A) 요일·시간별 평균\n",
    "    dow_hour_mean = (\n",
    "        train_df\n",
    "        .groupby(['building_number', 'hour', 'day_of_week'])['power_consumption']\n",
    "        .mean()\n",
    "        .reset_index(name='dow_hour_mean')\n",
    "    )\n",
    "    dow_hour_std = (\n",
    "        train_df\n",
    "        .groupby(['building_number', 'hour', 'day_of_week'])['power_consumption']\n",
    "        .std()\n",
    "        .reset_index(name='dow_hour_std')\n",
    "    )\n",
    "    df = df.merge(dow_hour_mean, on=['building_number', 'hour', 'day_of_week'], how='left')\n",
    "    df = df.merge(dow_hour_std,  on=['building_number', 'hour', 'day_of_week'], how='left')\n",
    "\n",
    "    # 3-B) holiday_mean & holiday_std\n",
    "    hol_mean = (\n",
    "        train_df\n",
    "        .groupby(['building_number', 'hour', 'holiday'])['power_consumption']\n",
    "        .mean()\n",
    "        .reset_index(name='holiday_mean')\n",
    "    )\n",
    "    hol_std = (\n",
    "        train_df\n",
    "        .groupby(['building_number', 'hour', 'holiday'])['power_consumption']\n",
    "        .std()\n",
    "        .reset_index(name='holiday_std')\n",
    "    )\n",
    "    df = df.merge(hol_mean, on=['building_number', 'hour', 'holiday'], how='left')\n",
    "    df = df.merge(hol_std,  on=['building_number', 'hour', 'holiday'], how='left')\n",
    "\n",
    "    # 3-C) 시간(hour)별 평균·표준편차\n",
    "    hr_mean = (\n",
    "        train_df\n",
    "        .groupby(['building_number', 'hour'])['power_consumption']\n",
    "        .mean()\n",
    "        .reset_index(name='hour_mean')\n",
    "    )\n",
    "    hr_std = (\n",
    "        train_df\n",
    "        .groupby(['building_number', 'hour'])['power_consumption']\n",
    "        .std()\n",
    "        .reset_index(name='hour_std')\n",
    "    )\n",
    "    df = df.merge(hr_mean, on=['building_number', 'hour'], how='left')\n",
    "    df = df.merge(hr_std,  on=['building_number', 'hour'], how='left')\n",
    "\n",
    "        # 3-D) month·hour별 평균·표준편차\n",
    "    mh_mean = (\n",
    "        train_df\n",
    "        .groupby(['building_number', 'month', 'hour'])['power_consumption']\n",
    "        .mean()\n",
    "        .reset_index(name='month_hour_mean')\n",
    "    )\n",
    "    mh_std = (\n",
    "        train_df\n",
    "        .groupby(['building_number', 'month', 'hour'])['power_consumption']\n",
    "        .std()\n",
    "        .reset_index(name='month_hour_std')\n",
    "    )\n",
    "    df = df.merge(mh_mean, on=['building_number', 'month', 'hour'], how='left')\n",
    "    df = df.merge(mh_std,  on=['building_number', 'month', 'hour'], how='left')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9d36b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "KR_HOLIDAYS_2024 = {\"2024-06-06\", \"2024-08-15\"}\n",
    "def _ensure_dt(df):\n",
    "    if not np.issubdtype(df[\"date_time\"].dtype, np.datetime64):\n",
    "        df[\"date_time\"] = pd.to_datetime(df[\"date_time\"])\n",
    "    return df\n",
    "\n",
    "def _nth_weekday_in_month(series_dt, weekday_target):\n",
    "    # 월 내 해당 요일의 n번째 (1=첫째, 2=둘째, ...)\n",
    "    first_of_month = series_dt.values.astype(\"datetime64[M]\").astype(\"datetime64[ns]\")\n",
    "    first_weekday = pd.to_datetime(first_of_month).weekday\n",
    "    weekday = series_dt.dt.weekday.values\n",
    "    day = series_dt.dt.day.values\n",
    "    first_occ_day = 1 + ((weekday_target - first_weekday) % 7)\n",
    "    nth = ((day - first_occ_day) // 7) + 1\n",
    "    nth = np.where(day >= first_occ_day, nth, 0)\n",
    "    return nth\n",
    "\n",
    "def add_holiday(df: pd.DataFrame, kr_holidays: set[str] = None) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    _ensure_dt(df)\n",
    "    if kr_holidays is None:\n",
    "        kr_holidays = KR_HOLIDAYS_2024\n",
    "\n",
    "    # 기본 파생 (is_weekend은 '계산만' 하고 이후 어떤 건물에도 수정하지 않음)\n",
    "    df[\"weekday\"] = df[\"date_time\"].dt.weekday          # 0=Mon..6=Sun\n",
    "    df[\"date\"]    = df[\"date_time\"].dt.date\n",
    "    df[\"is_weekend\"] = (df[\"weekday\"] >= 5).astype(int) # 그대로 유지\n",
    "    df[\"holiday\"] = 0\n",
    "\n",
    "    # 공휴일 여부는 컬럼으로 저장하지 않고, 로컬 불리언으로만 사용\n",
    "    is_kr = df[\"date\"].astype(str).isin(kr_holidays).values\n",
    "\n",
    "    bt = df[\"building_type\"]\n",
    "\n",
    "    # ── Apartment: 항상 영업\n",
    "    mm = bt == \"Apartment\"\n",
    "    df.loc[mm, \"holiday\"] = 0\n",
    "\n",
    "    # ── Hospital: 주말 or 공휴일 휴식\n",
    "    mm = bt == \"Hospital\"\n",
    "    if mm.any():\n",
    "        df.loc[mm, \"holiday\"] = (df.loc[mm, \"is_weekend\"].values | is_kr[mm]).astype(int)\n",
    "\n",
    "    # ── Public: 기본 주말 or 공휴일 휴식, 단 33/92는 항상 영업\n",
    "    mm = bt == \"Public\"\n",
    "    if mm.any():\n",
    "        df.loc[mm, \"holiday\"] = (df.loc[mm, \"is_weekend\"].values | is_kr[mm]).astype(int)\n",
    "        mm_always_open = df[\"building_number\"].isin([33, 92])\n",
    "        df.loc[mm_always_open, \"holiday\"] = 0\n",
    "\n",
    "    # ── Hotel: 항상 영업\n",
    "    mm = bt == \"Hotel\"\n",
    "    df.loc[mm, \"holiday\"] = 0\n",
    "\n",
    "    # ── School: 주말 or 공휴일 휴식\n",
    "    mm = bt == \"School\"\n",
    "    if mm.any():\n",
    "        df.loc[mm, \"holiday\"] = (df.loc[mm, \"is_weekend\"].values | is_kr[mm]).astype(int)\n",
    "\n",
    "    # ── IDC(전화국): 개별 규칙\n",
    "    mm_idc = bt == \"IDC\"\n",
    "    if mm_idc.any():\n",
    "        # 36,43,52: 주말 or 공휴일\n",
    "        ids = [36, 43, 52]\n",
    "        mmx = df[\"building_number\"].isin(ids)\n",
    "        df.loc[mmx, \"holiday\"] = (df.loc[mmx, \"is_weekend\"].values | is_kr[mmx]).astype(int)\n",
    "        # 64: 주말만\n",
    "        mmx = df[\"building_number\"].eq(64)\n",
    "        df.loc[mmx, \"holiday\"] = df.loc[mmx, \"is_weekend\"].astype(int)\n",
    "        # 67: 주말 + 8/15\n",
    "        mmx = df[\"building_number\"].eq(67)\n",
    "        if mmx.any():\n",
    "            df.loc[mmx, \"holiday\"] = df.loc[mmx, \"is_weekend\"].astype(int)\n",
    "            df.loc[mmx & (df[\"date\"].astype(str) == \"2024-08-15\"), \"holiday\"] = 1\n",
    "        # 30,35,57: 휴일 없음 → holiday=0 유지\n",
    "\n",
    "    # ── Commercial: 개별 규칙\n",
    "    mm = bt == \"Commercial\"\n",
    "    if mm.any():\n",
    "        # 2: 주말만\n",
    "        mmx = df[\"building_number\"].eq(2)\n",
    "        df.loc[mmx, \"holiday\"] = df.loc[mmx, \"is_weekend\"].astype(int)\n",
    "        # 6,16,20,51,86: 주말 or 공휴일\n",
    "        ids = [6, 16, 20, 51, 86]\n",
    "        mmx = df[\"building_number\"].isin(ids)\n",
    "        df.loc[mmx, \"holiday\"] = (df.loc[mmx, \"is_weekend\"].values | is_kr[mmx]).astype(int)\n",
    "        # 41,56,76,99: 휴일 없음 → holiday=0 유지\n",
    "\n",
    "    # ── Other Buildings: 개별 규칙\n",
    "    # 26: 월/화\n",
    "    mmx = df[\"building_number\"].eq(26)\n",
    "    df.loc[mmx, \"holiday\"] = df.loc[mmx, \"weekday\"].isin([0, 1]).astype(int)\n",
    "    # 82: 월\n",
    "    mmx = df[\"building_number\"].eq(82)\n",
    "    df.loc[mmx, \"holiday\"] = df.loc[mmx, \"weekday\"].eq(0).astype(int)\n",
    "    # 47,69: 주말 or 공휴일\n",
    "    mmx = df[\"building_number\"].isin([47, 69])\n",
    "    df.loc[mmx, \"holiday\"] = (df.loc[mmx, \"is_weekend\"].values | is_kr[mmx]).astype(int)\n",
    "    # 58,61,78: 주말에도 영업 → holiday=0 유지 (is_weekend는 건드리지 않음)\n",
    "    # 97: 토요일만\n",
    "    mmx = df[\"building_number\"].eq(97)\n",
    "    df.loc[mmx, \"holiday\"] = df.loc[mmx, \"weekday\"].eq(5).astype(int)\n",
    "\n",
    "    # ── Department Store: 공휴일에도 영업. 개별 규칙만 휴일 처리.\n",
    "    mm = bt == \"Department Store\"\n",
    "    if mm.any():\n",
    "        df.loc[mm, \"holiday\"] = 0\n",
    "\n",
    "        nth_sun = _nth_weekday_in_month(df[\"date_time\"], 6)  # Sun\n",
    "        nth_mon = _nth_weekday_in_month(df[\"date_time\"], 0)  # Mon\n",
    "\n",
    "        def mark_nth_weekday(building, weekday, nth_set):\n",
    "            if weekday == 6:\n",
    "                nth = nth_sun\n",
    "            elif weekday == 0:\n",
    "                nth = nth_mon\n",
    "            else:\n",
    "                nth = _nth_weekday_in_month(df[\"date_time\"], weekday)\n",
    "            sel = df[\"building_number\"].eq(building) & df[\"weekday\"].eq(weekday) & pd.Series(nth).isin(list(nth_set)).values\n",
    "            df.loc[sel, \"holiday\"] = 1\n",
    "\n",
    "        # 매주/격주/특정일\n",
    "        df.loc[df[\"building_number\"].eq(18) & df[\"weekday\"].eq(6), \"holiday\"] = 1  # 18: 매주 일요일\n",
    "\n",
    "        special = {\n",
    "            19: [\"2024-06-10\", \"2024-07-08\", \"2024-08-19\"],\n",
    "            45: [\"2024-06-10\", \"2024-07-08\", \"2024-08-19\"],\n",
    "            54: [\"2024-06-17\", \"2024-07-01\", \"2024-08-19\"],\n",
    "            74: [\"2024-06-17\", \"2024-07-01\"],\n",
    "            79: [\"2024-06-17\", \"2024-07-01\", \"2024-08-19\"],\n",
    "            95: [\"2024-07-08\", \"2024-08-05\"],\n",
    "            29: [\"2024-06-10\", \"2024-07-10\", \"2024-08-10\"],\n",
    "        }\n",
    "        for b, dates in special.items():\n",
    "            sel = df[\"building_number\"].eq(b) & df[\"date\"].astype(str).isin(dates)\n",
    "            df.loc[sel, \"holiday\"] = 1\n",
    "\n",
    "        # 격주 규칙\n",
    "        mark_nth_weekday(27, 6, {2, 4})  # 27: 2·4번째 일요일\n",
    "        mark_nth_weekday(29, 6, {4})     # 29: 4번째 일요일\n",
    "        mark_nth_weekday(32, 0, {2, 4})  # 32: 2·4번째 월요일\n",
    "        for b in [40, 59, 63]:           # 2·4번째 일요일\n",
    "            mark_nth_weekday(b, 6, {2, 4})\n",
    "\n",
    "        # 34,73,88: 휴일 없음 → holiday=0 유지\n",
    "\n",
    "    # 안전 재확인: IDC 67의 8/15\n",
    "    df.loc[(df[\"building_number\"].eq(67)) & (df[\"date\"].astype(str) == \"2024-08-15\"), \"holiday\"] = 1\n",
    "\n",
    "    return df\n",
    "\n",
    "def remove_outliers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    _ensure_dt(df)\n",
    "\n",
    "    rules_lt = [\n",
    "        # (building_number, threshold)\n",
    "        # Apartment\n",
    "        (25, 0, \"eq\"), (70, 200, \"lt\"),\n",
    "        # Hospital\n",
    "        (44, 800, \"lt\"), (90, 800, \"lt\"), (42, 2000, \"lt\"), (17, 1000, \"lt\"),\n",
    "        # Public\n",
    "        (68, 600, \"lt\"), (72, 600, \"lt\"), (80, 600, \"lt\"), (92, 200, \"lt\"),\n",
    "        # Hotel\n",
    "        (98, 500, \"lt\"),\n",
    "        # Other\n",
    "        (97, 500, \"lt\"), (78, 400, \"lt\"), (26, 300, \"lt\"), (7, 2000, \"lt\"),\n",
    "        # Commercial\n",
    "        (76, 2000, \"lt\"), (41, 2200, \"lt\"), (20, 1600, \"lt\"),\n",
    "        # School\n",
    "        (5, 2000, \"lt\"), (8, 250, \"lt\"), (12, 3500, \"lt\"),\n",
    "        # IDC\n",
    "        (67, 7333, \"lt\"), (81, 800, \"lt\"), (52, 2000, \"lt\"), (43, 6000, \"lt\"), (30, 8000, \"lt\"),\n",
    "    ]\n",
    "\n",
    "    # 값 기반 제거\n",
    "    mask_ok = pd.Series(True, index=df.index)\n",
    "    pc = df[\"power_consumption\"]\n",
    "    bnum = df[\"building_number\"]\n",
    "\n",
    "    for bn, th, op in rules_lt:\n",
    "        if op == \"lt\":\n",
    "            mask_ok &= ~((bnum.eq(bn)) & (pc < th))\n",
    "        elif op == \"eq\":\n",
    "            mask_ok &= ~((bnum.eq(bn)) & (pc == th))\n",
    "\n",
    "    # 기간 기반 제거\n",
    "    # Hotel 10: 2024-07-05 ~ 2024-08-22\n",
    "    mask_ok &= ~(\n",
    "        (bnum.eq(10)) &\n",
    "        (df[\"date_time\"].between(pd.Timestamp(\"2024-07-05\"), pd.Timestamp(\"2024-08-22\")))\n",
    "    )\n",
    "    # IDC 57: 2024-06-07 이전\n",
    "    mask_ok &= ~(\n",
    "        (bnum.eq(57)) & (df[\"date_time\"] < pd.Timestamp(\"2024-06-07\"))\n",
    "    )\n",
    "    # Research 94: 2024-07-27 09:00 ~ 2024-08-04 23:00\n",
    "    mask_ok &= ~(\n",
    "        (bnum.eq(94)) &\n",
    "        (df[\"date_time\"].between(pd.Timestamp(\"2024-07-27 09:00\"), pd.Timestamp(\"2024-08-04 23:00\")))\n",
    "    )\n",
    "\n",
    "    return df.loc[mask_ok].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ce670be",
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP_COLS = ['sunshine','solar_radiation', 'solar_power_capacity','ess_capacity', 'pcs_capacity', \n",
    "             'hour', 'day_of_week', 'day_of_year']\n",
    "CAT_COLS = ['building_type', 'building_number']\n",
    "GROUP_COLS =  [\"building_number\",\"hour\",\"day_of_week\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "056333ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to: ../data/processed/train.pkl\n",
      "Saved processed data to: ../data/processed/test.pkl\n"
     ]
    }
   ],
   "source": [
    "train, test = load_and_process(\"./data\")\n",
    "train, test = create_datetime(train), create_datetime(test)\n",
    "combined_df = pd.concat([train, test], ignore_index=True)\n",
    "combined_df = add_holiday(combined_df) \n",
    "combined_df = remove_outliers(combined_df)\n",
    "combined_df = add_squared_features(combined_df)\n",
    "combined_df = add_summer_cycle_features(combined_df)\n",
    "combined_df = create_cyclic_features(combined_df)\n",
    "comgined_df = add_cdh_feature(combined_df)\n",
    "combined_df = add_cdd_feature(combined_df)\n",
    "combined_df = add_thi_feature(combined_df)\n",
    "combined_df = add_wct_feature(combined_df)\n",
    "combined_df = add_temp_features(combined_df)\n",
    "combined_df = add_humid_features(combined_df)\n",
    "combined_df = mean_std_power(combined_df)\n",
    "combined_df = add_weekly_slope(combined_df)\n",
    "combined_df = combined_df.drop(DROP_COLS, axis=1)\n",
    "\n",
    "split_date = pd.to_datetime('2024-08-25 00:00:00')\n",
    "train = combined_df[combined_df['date_time'] < split_date].copy()\n",
    "test  = combined_df[combined_df['date_time'] >= split_date].copy()\n",
    "for c in CAT_COLS:\n",
    "    train[c] = train[c].astype('category')\n",
    "    test[c]  = test[c].astype('category')\n",
    "train = train.ffill() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dccdc9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['건물번호'] = train['building_number']\n",
    "test['건물번호'] = test['building_number']\n",
    "\n",
    "train['일시'] = train['date_time']\n",
    "test['일시'] = test['date_time']\n",
    "\n",
    "train['일시'] = pd.to_datetime(train['일시'], format='%Y-%m-%d %H:%M:%S')\n",
    "test['일시'] = pd.to_datetime(test['일시'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "train['전력소비량(kWh)'] = train['power_consumption']\n",
    "\n",
    "train = train.drop(['building_number', 'date_time', 'power_consumption','building_type'], axis=1)\n",
    "test = test.drop(['building_number', 'date_time','building_type'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5481c814",
   "metadata": {},
   "source": [
    "## Train & Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a83012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking_ml_datasets(model, X_train_n, y_train_n, X_test_n, n_folds, fitting=True):\n",
    "    \n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "    \n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0], 1))\n",
    "    test_pred = np.zeros((X_test_n.shape[0], n_folds))\n",
    "    \n",
    "    for folder_counter, (train_index, valid_index) in enumerate(kf.split(X_train_n, y_train_n)):\n",
    "        X_tr = X_train_n[train_index]\n",
    "        y_tr = y_train_n[train_index]\n",
    "        X_te = X_train_n[valid_index]\n",
    "\n",
    "        if fitting == True:\n",
    "            model.fit(X_tr, y_tr)\n",
    "            \n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1,1)\n",
    "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
    "        \n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)    \n",
    "    \n",
    "    return train_fold_pred, test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "015a4a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:10:41<00:00, 42.42s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16800,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabpfn = TabPFNRegressor(random_state=seed, n_jobs=-1)\n",
    "best_ml = [    tabpfn]\n",
    "preds_total = []\n",
    "\n",
    "for b_num in tqdm(train['건물번호'].unique()):\n",
    "    \n",
    "    train_df = train[train[\"건물번호\"]==b_num]\n",
    "    test_df = test[test[\"건물번호\"]==b_num]\n",
    "\n",
    "    X_train = train_df.drop(['건물번호', '일시','date', '전력소비량(kWh)'], axis=1)\n",
    "    y_train = train_df['전력소비량(kWh)'].values\n",
    "\n",
    "    X_test = test_df.drop(['건물번호','date', '일시', 'power_consumption'], axis=1)\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    meta_X_train=[]\n",
    "    meta_X_test=[]\n",
    "    \n",
    "    for idx, estimator in enumerate(best_ml):\n",
    "        \n",
    "        temp_X_train, temp_X_test = get_stacking_ml_datasets(\n",
    "            estimator, X_train, y_train, X_test, cv\n",
    "        )\n",
    "        \n",
    "        meta_X_train.append(temp_X_train)\n",
    "        meta_X_test.append(temp_X_test)\n",
    "        \n",
    "    meta_X_train = np.hstack(meta_X_train)\n",
    "    meta_X_test = np.hstack(meta_X_test)\n",
    "\n",
    "    meta_clf = LinearRegression()\n",
    "    meta_clf.fit(meta_X_train, y_train)\n",
    "    preds_partial = meta_clf.predict(meta_X_test)\n",
    "    \n",
    "    preds_total.append(preds_partial)\n",
    "\n",
    "prediction = np.hstack(preds_total)\n",
    "\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4552aa04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_date_time</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_20240825 00</td>\n",
       "      <td>3937.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_20240825 01</td>\n",
       "      <td>3670.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_20240825 02</td>\n",
       "      <td>3508.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_20240825 03</td>\n",
       "      <td>3068.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_20240825 04</td>\n",
       "      <td>2828.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_date_time   answer\n",
       "0  1_20240825 00  3937.22\n",
       "1  1_20240825 01  3670.49\n",
       "2  1_20240825 02  3508.39\n",
       "3  1_20240825 03  3068.38\n",
       "4  1_20240825 04  2828.17"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv('./data/sample_submission.csv')\n",
    "submission['answer'] = np.round(prediction, 2)\n",
    "submission.to_csv('pfn_stacking.csv', index=False)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabpfn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
